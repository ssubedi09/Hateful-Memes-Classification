{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "50178988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, default_data_collator\n",
    "from datasets import Dataset, load_dataset, Features, Value, ClassLabel\n",
    "from evaluate import load\n",
    "from accelerate import Accelerator\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470c012",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (330623600.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[104], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    raw = load_dataset(\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# Check device availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "features = Features({\n",
    "    \"id\":    Value(\"string\"),\n",
    "    \"img\":   Value(\"string\"),\n",
    "    \"label\": ClassLabel(names=[\"clean\", \"hateful\"]),\n",
    "    \"text\":  Value(\"string\"),\n",
    "})\n",
    "\n",
    "raw = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\":      \"../data/train.jsonl\",\n",
    "        \"validation\": \"../data/dev.jsonl\",\n",
    "        \"test\":       \"../data/test.jsonl\",\n",
    "    },\n",
    "    split=None,\n",
    "    features=features,    \n",
    "\n",
    "\n",
    "train_it  = raw[\"train\"]                  \n",
    "valid_it  = raw['validation']\n",
    "test_it   = raw['test']\n",
    "\n",
    "labels = train_it[\"label\"]            # list of 0/1\n",
    "counts = Counter(labels)\n",
    "total   = counts[0] + counts[1]\n",
    "freqs   = [counts[0] / total, counts[1] / total]\n",
    "\n",
    "class_weights = torch.tensor([1/f for f in freqs], dtype=torch.float32, device=device)\n",
    "print(\"Using class‑weights:\", class_weights.tolist())\n",
    "\n",
    "tokzr = AutoTokenizer.from_pretrained(\"GroNLP/hatebert\")\n",
    "\n",
    "def preprocess(batch):\n",
    "    enc = tokzr(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,           # memes are short\n",
    "        return_attention_mask=True,\n",
    "        # return_tensors=\"pt\"\n",
    "    )\n",
    "    enc[\"labels\"] = batch[\"label\"]\n",
    "    return enc\n",
    "\n",
    "tokenised_train = train_it.map(preprocess, remove_columns=[\"id\", \"img\", \"text\",\"label\"])\n",
    "tokenised_val   = valid_it.map(preprocess, remove_columns=[\"id\", \"img\", \"text\",\"label\"])\n",
    "tokenised_test  = test_it.map(preprocess, remove_columns=[\"id\", \"img\", \"text\",\"label\"])\n",
    "\n",
    "train_loader = DataLoader(tokenised_train, batch_size=8, collate_fn=default_data_collator)\n",
    "val_loader   = DataLoader(tokenised_val,   batch_size=8, collate_fn=default_data_collator)\n",
    "test_loader  = DataLoader(tokenised_test,  batch_size=8, collate_fn=default_data_collator)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"GroNLP/hatebert\", num_labels=2)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "    model, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "de8c2380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 – training:   3%|▎         | 30/1063 [00:38<21:49,  1.27s/it, loss=0.525] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 18\u001b[0m\n\u001b[1;32m     12\u001b[0m loss    \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(\n\u001b[1;32m     13\u001b[0m     logits,\n\u001b[1;32m     14\u001b[0m     batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     15\u001b[0m     weight\u001b[38;5;241m=\u001b[39mclass_weights\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m accelerator\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m---> 18\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m train_bar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(loss))\n",
      "File \u001b[0;32m~/cs7643/cs7643-project/hatebert-env/lib/python3.10/site-packages/accelerate/optimizer.py:166\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_patched_step_method\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called:\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# If the optimizer step was skipped, gradient overflow was detected.\u001b[39;00m\n",
      "File \u001b[0;32m~/cs7643/cs7643-project/hatebert-env/lib/python3.10/site-packages/torch/amp/grad_scaler.py:461\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    459\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 461\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/cs7643/cs7643-project/hatebert-env/lib/python3.10/site-packages/torch/amp/grad_scaler.py:355\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    349\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    354\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    356\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/cs7643/cs7643-project/hatebert-env/lib/python3.10/site-packages/torch/amp/grad_scaler.py:355\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    349\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    354\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    356\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs      = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ───────────────── TRAIN ──────────────────\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader,  # iterate over the loader itself\n",
    "                     desc=f\"Epoch {epoch+1} – training\",\n",
    "                     total=None)    # unknown length is fine\n",
    "\n",
    "    for batch in train_bar:\n",
    "        logits = model(**batch).logits\n",
    "        loss    = F.cross_entropy(\n",
    "            logits,\n",
    "            batch['labels'],\n",
    "            weight=class_weights\n",
    "        )\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_bar.set_postfix(loss=float(loss))\n",
    "    \n",
    "    model.eval()\n",
    "    model.eval()\n",
    "    preds, golds = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} – validation\"):\n",
    "            logits = model(**batch).logits\n",
    "            preds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "            golds.extend(batch[\"labels\"].cpu().tolist())\n",
    "\n",
    "    macro_f1 = f1_score(golds, preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_f1 = f1_score(golds, preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d01b410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 – Val macro‑F1: 0.363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nEpoch {epoch+1} – Val macro‑F1: {macro_f1:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_loader(loader, max_batches=None):\n",
    "    \"\"\"\n",
    "    Iterate through a (streaming) DataLoader once and return:\n",
    "      • total number of samples\n",
    "      • Counter mapping class‑id → count\n",
    "    If max_batches is given, stop after that many batches.\n",
    "    \"\"\"\n",
    "    total  = 0\n",
    "    label_counts = Counter()\n",
    "\n",
    "    iterable = loader\n",
    "    if max_batches is not None:\n",
    "        iterable = iter(loader)\n",
    "        iterable = (next(iterable) for _ in range(max_batches))\n",
    "\n",
    "    for batch in tqdm(iterable, desc=\"Counting\"):\n",
    "        labels = batch[\"labels\"].cpu().tolist()\n",
    "        label_counts.update(labels)\n",
    "        total += len(labels)\n",
    "\n",
    "    return total, label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "803ea2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting: 100%|██████████| 1063/1063 [00:02<00:00, 440.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 8500\n",
      "Class split: Counter({0: 5450, 1: 3050})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_total, train_split = count_loader(train_loader)\n",
    "print(\"Train samples:\", train_total)\n",
    "print(\"Class split:\", train_split)    # e.g. Counter({0: 8600, 1: 4320})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fba6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5364320633196245"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6913 / (6913+5974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f87f518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting: 100%|██████████| 63/63 [00:00<00:00, 406.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 500\n",
      "Class split: Counter({0: 253, 1: 247})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_total, val_split = count_loader(val_loader)\n",
    "print(\"Validation samples:\", val_total)\n",
    "print(\"Class split:\", val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "96ca285f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1062"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8500//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe60b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hatebert-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
